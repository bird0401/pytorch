{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-7_SSD_training.ipynb",
      "provenance": [],
      "mount_file_id": "19wuAY8DEC8HF87gmxkTWnT33r6Yh7bq7",
      "authorship_tag": "ABX9TyNVmZVhgnlZmg6Gs7/azo4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mot1122/study_pytorch/blob/main/2_7_SSD_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r /content/drive/MyDrive/pytorch_advanced/2_objectdetection/utils/ utils"
      ],
      "metadata": {
        "id": "2_iuVuZYjdRp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ag2bRlm1g8qH"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import random\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "metadata": {
        "id": "19zwUIjuhqsi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcZA-GJ2hyUe",
        "outputId": "f90b9b44-d587-45ad-d29e-4e61afb75bc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.ssd_model import make_datapath_list,VOCDataset,DataTransform,Anno_xml2list,od_collate_fn\n",
        "rootpath=\"/content/drive/MyDrive/pytorch_advanced/2_objectdetection/data/VOCdevkit/VOC2012/\"\n",
        "train_img_path,train_anno_path,val_img_path,val_anno_path=make_datapath_list(rootpath)\n",
        "voc_classes= ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "               'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant',\n",
        "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
        "input_size = 300  # 画像のinputサイズを300×300にする\n",
        "train_dataset=VOCDataset(train_img_path,train_anno_path,phase=\"train\",transform=DataTransform(input_size,color_mean),transform_anno=Anno_xml2list(voc_classes))\n",
        "val_dataset=VOCDataset(val_img_path,val_anno_path,phase=\"val\",transform=DataTransform(input_size,color_mean),transform_anno=Anno_xml2list(voc_classes))\n",
        "batch_size=32\n",
        "train_dataloader=data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=od_collate_fn)\n",
        "val_dataloader=data.DataLoader(val_dataset,batch_size=batch_size,shuffle=False,collate_fn=od_collate_fn)\n",
        "dataloader_dict={\"train\":train_dataloader,\"val\":val_dataloader}"
      ],
      "metadata": {
        "id": "l-XVAzxsiCCa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.ssd_model import SSD\n",
        "ssd_cfg={\n",
        "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
        "    'input_size': 300,  # 画像の入力サイズ\n",
        "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
        "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
        "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
        "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
        "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
        "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
        "}\n",
        "net=SSD(phase=\"train\",cfg=ssd_cfg)\n",
        "vgg_weights=torch.load(\"/content/drive/MyDrive/pytorch_advanced/2_objectdetection/weights/vgg16_reducedfc.pth\")\n",
        "net.vgg.load_state_dict(vgg_weights)\n",
        "\n",
        "def weights_init(m):\n",
        "  if isinstance(m,nn.Conv2d): \n",
        "    init.kaiming_normal_(m.weight.data)\n",
        "    if m.bias is not None: nn.init.constant_(m.bias,0.0)\n",
        "\n",
        "net.extras.apply(weights_init)\n",
        "net.loc.apply(weights_init)\n",
        "net.conf.apply(weights_init)\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "print(\"loaded weghts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3zPT2yP-WRP",
        "outputId": "56466dbd-bf93-4b15-e704-0b2c5860a01e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "loaded weghts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.ssd_model import MultiBoxLoss\n",
        "\n",
        "criterion=MultiBoxLoss(jaccard_thresh=0.5,neg_pos=3,device=device)\n",
        "optimizer=optim.SGD(net.parameters(),lr=1e-3,momentum=0.9,weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "0HVDqqkxFibR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(net,dataloaders_dict,criterion,optimizer,num_epochs):\n",
        "  device=torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
        "  print(f\"device: {device}\")\n",
        "  net.to(device)\n",
        "  iterattion=1\n",
        "  epoch_train_loss=0.0\n",
        "  epoch_val_loss=0.0\n",
        "  logs=[]\n",
        "  for epoch in range(num_epochs+1):\n",
        "    t_epoch_start=time.time()\n",
        "    t_iter_start=time.time()\n",
        "    print(f\"{epoch}/{num_epochs}\")\n",
        "    for phase in [\"train\",\"val\"]:\n",
        "      if phase==\"train\":\n",
        "        net.train()\n",
        "        print(\"train\")\n",
        "      else:\n",
        "        if ((epoch+1)%10==0):\n",
        "          net.eval()\n",
        "          print(\"val\")\n",
        "        else:continue\n",
        "      for images,targets in dataloaders_dict[\"phase\"]:\n",
        "        images=images.to(device)\n",
        "        targets=[anno.to(device) for anno in targets]\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(phase=\"train\"):\n",
        "          outputs=net(images)\n",
        "          loss_l,loss_c=criterion(outputs,targets)\n",
        "          loss=loss_l+loss_c\n",
        "          if phase==\"train\":\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_value_(net.parameters(),clip_value=2.0)\n",
        "            optimizer.step()\n",
        "            if iteration%10==0:\n",
        "              t_iter_finish=time.time()\n",
        "              print(f\"iteration: {iteration}, loss: {loss}, {t_iter_finish-t_iter_start}\")\n",
        "              t_iter_start=time.time()\n",
        "            epoch_train_loss+=loss.item()\n",
        "            iteration+=1\n",
        "          else:epoch_val_loss+=loss.item()\n",
        "    t_epoch_finish=time.time()\n",
        "    print(f\"epoch: {epoch}, train loss: {epoch_train_loss}, val loss: {epoch_val_loss}, {t_epoch_finish-t_epoch_start}sec\")\n",
        "    t_epoch_start=time.time()\n",
        "    log_epoch={\"epoch\":epoch+1, \"train_loss\":epoch_train_loss, \"val_loss\":epoch_val_loss}\n",
        "    logs.append(log_epoch)\n",
        "    df=pd.DataFrame(logs)\n",
        "    df.to_csv(\"log_output.csv\")\n",
        "    epoch_train_loss,epoch_val_loss=0.0,0.0\n",
        "    if ((epoch+1)%10==0):torch.save(net.state_dict(),'weights/ssd300_' + str(epoch+1) + '.pth')"
      ],
      "metadata": {
        "id": "JgRybfDiHJZp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=50\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "IPyLTilikniO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}